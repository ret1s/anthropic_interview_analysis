{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Anthropic Interviewer dataset\n",
        "\n",
        "Quickstart notebook to pull the transcripts from the Hugging Face dataset and do light inspection.\n",
        "            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Dataset:** `Anthropic/AnthropicInterviewer` on Hugging Face.\n",
        "- Interview transcripts from 1,250 professionals (workforce=1,000, creatives=125, scientists=125).\n",
        "- Data is CC-BY; code MIT. Public dataset, so no auth token needed for reading.\n",
        "\n",
        "Run the install cell once per environment, then execute the rest.\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "setup"
        ]
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "%pip install -q pandas huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "SPLITS = {\n",
        "    \"workforce\": \"interview_transcripts/workforce_transcripts.csv\",\n",
        "    \"creatives\": \"interview_transcripts/creatives_transcripts.csv\",\n",
        "    \"scientists\": \"interview_transcripts/scientists_transcripts.csv\",\n",
        "}\n",
        "BASE_PATH = \"hf://datasets/Anthropic/AnthropicInterviewer/\"\n",
        "\n",
        "def load_split(name: str) -> pd.DataFrame:\n",
        "    path = BASE_PATH + SPLITS[name]\n",
        "    df = pd.read_csv(path)\n",
        "    df[\"split\"] = name\n",
        "    return df\n",
        "\n",
        "dfs = {name: load_split(name) for name in SPLITS}\n",
        "for name, df in dfs.items():\n",
        "    cols = \", \".join(df.columns)\n",
        "    print(f\"{name:10} {df.shape[0]:4} rows | columns: {cols}\")\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Quick look at the workforce split\n",
        "dfs[\"workforce\"].head()\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Sample rows across all splits\n",
        "all_df = pd.concat(dfs.values(), ignore_index=True)\n",
        "all_df.sample(5, random_state=42)[[\"transcript_id\", \"split\", \"text\"]]\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Rough length stats by split (character count of transcript text)\n",
        "all_df = all_df.copy()\n",
        "all_df[\"text_length\"] = all_df[\"text\"].str.len()\n",
        "all_df.groupby(\"split\")[\"text_length\"].describe()[[\"count\", \"mean\", \"min\", \"max\"]]\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: persist the three splits locally in data/\n",
        "output_dir = Path(\"data\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "for name, df in dfs.items():\n",
        "    dest = output_dir / f\"{name}_transcripts.csv\"\n",
        "    df.to_csv(dest, index=False)\n",
        "    print(f\"Wrote {dest}\")\n",
        "            \n"
      ]
    }
  ]
}